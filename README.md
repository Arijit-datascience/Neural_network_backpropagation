# EVA6_Session4_Backpropagation_and_Architectural_Basics

Here we are working on a two part problem, please follow the links to access corresponding contents:

### 1. Implementing Backpropagation in excel:

This is a very exciting activity to understand how Backpropagation actually works, using the very versatile and helpful tool, MS Excel. Click [HERE](https://github.com/Arijit-datascience/Neural_network_backpropagation/tree/main/Backpropagation%20Calculation) to see more.

### 2. Implement a MNIST digit identifer to achieve 99.4% Accuracy:

Moving onto coding, we have implemented MNIST digit identifier based on some basic Architectural concepts like MaxPooling, Global Average Pooling (GAP), Batch Normalization and DropOut. Click [HERE](https://github.com/Arijit-datascience/Neural_network_backpropagation/tree/main/MNIST%20Digit%20Recognition)  to access the code and read more about the implementation.


### Collaborators:

Abhiram Gurijala  
Arijit Ganguly  
Rohin Sequeira  
